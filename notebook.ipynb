{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset has been loaded in split into training and test data\n"
     ]
    }
   ],
   "source": [
    "from package.src.loading import DataLoader\n",
    "loader = DataLoader('./data/kidney_disease.csv',test_size=0.1)\n",
    "loader.load(target_column=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data Preprocessing for the train data is starting\n",
      "We infer missing data\n",
      "Inference of missing data is Done\n",
      "We correct typos in the data\n",
      "Typo detected on column : dm betwen  \tyes and   yes\n",
      "Typo corrected\n",
      "Typo detected on column : dm betwen  \tyes and  yes\n",
      "Typo corrected\n",
      "Typo detected on column : dm betwen   yes and  yes\n",
      "Typo corrected\n",
      "Typo detected on column : dm betwen  \tno and  no\n",
      "Typo corrected\n",
      "Typo detected on column : cad betwen  \tno and  no\n",
      "Typo corrected\n",
      "Typo detected on column : classification betwen  ckd\t and  ckd\n",
      "Typo corrected\n",
      "Typos correction is Done\n",
      "We encode the categorical columns\n",
      "Columns encoding is Done\n",
      "Train Data preprocessing is done \n",
      "Data Preprocessing for the test data is starting\n",
      "We infer missing data\n",
      "Inference of missing data is Done\n",
      "We correct typos in the data\n",
      "Correction typos for test dataset for  rbc\n",
      "Correction typos for test dataset for  pc\n",
      "Correction typos for test dataset for  pcc\n",
      "Correction typos for test dataset for  ba\n",
      "Correction typos for test dataset for  htn\n",
      "Correction typos for test dataset for  dm\n",
      "Correction typos for test dataset for  cad\n",
      "Correction typos for test dataset for  appet\n",
      "Correction typos for test dataset for  pe\n",
      "Correction typos for test dataset for  ane\n",
      "Correction typos for test dataset for  classification\n",
      "Typos correction is Done\n",
      "We encode the categorical columns\n",
      "Columns encoding is Done\n",
      "Test Data preprocessing is done \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train,X_test,y_test = loader.X_train, loader.y_train, loader.X_test, loader.y_test\n",
    "from package.src.preprocessing import FeatureSelector\n",
    "from package.src.preprocessing import DataPreprocessor, DataNormaliser\n",
    "pp = DataPreprocessor(missing_data_strategy= \"mean\", categorical_encoding= \"label\")\n",
    "fs = FeatureSelector()\n",
    "dn = DataNormaliser()\n",
    "X_train,y_train= pp.fit_transform(X_train,y_train)\n",
    "X_test,y_test=pp.transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25 componenents (PCA)\n"
     ]
    }
   ],
   "source": [
    "dn.fit(X_train)\n",
    "X_train=dn.transform(X_train)\n",
    "X_test=dn.transform(X_test)\n",
    "fs.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data reduced to 20 dimensions\ndata reduced to 20 dimensions\n"
     ]
    }
   ],
   "source": [
    "X_train=fs.transform(X_train)\n",
    "X_test=fs.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from package.src.modeling import Model\n",
    "model = Model(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.fit(X_train,y_train)\n",
    "y_p = model.model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Precision  Recall  F1_score\n",
       "class 0          1       1       1.0\n",
       "class 1          1       1       1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>class 0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>class 1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model.f1_score_support(y_test,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, model):\n",
    "        if model not in [\"LogisticRegression\", \"DecisionTrees\",\"KNN\",\"SVM\",\"RandomForest\"]:\n",
    "            raise Exception(\"Model not supported \\n choose in list ....  \")\n",
    "        self.model = model\n",
    "        self.skmodel = None\n",
    "        self.params = None\n",
    "        if self.model == \"LogisticRegression\":\n",
    "            self.skmodel = LogisticRegression()\n",
    "            self.params = {'C': [0.001, .009, 0.01, .09, 1, 5, 10, 25]}\n",
    "        elif self.model == \"DecisionTrees\":\n",
    "            self.skmodel = DecisionTreeClassifier()\n",
    "            self.params ={'min_samples_split': range(10, 500, 20), 'max_depth': range(1, 20, 2), 'criterion': ['gini', 'entropy']}\n",
    "        elif self.model == \"KNN\":\n",
    "            self.skmodel = KneighborsClassifier()\n",
    "            self.params ={'n_neighbors': [4, 5, 6, 7], 'leaf_size': [1, 3, 5], 'weights': ['uniform', 'distance']}\n",
    "        elif self.model == \"SVM\":\n",
    "            self.skmodel = SVC()\n",
    "            self.params = {}\n",
    "        elif self.model == \"RandomForest\":\n",
    "            self.skmodel = RandomForestClassifier()\n",
    "            self.params = {}\n",
    "            \n",
    "    def fit(self,X,Y,params_dic): \n",
    "        if self.model == \"LogisticRegression\":\n",
    "            self.skmodel = LogisticRegression(params_dic)\n",
    "            self.skmodel.fit(X,Y)\n",
    "    def predict(self,X):\n",
    "        return self.skmodel.predict(X)\n",
    "\n",
    "    def cross_validation_score(self, X_train: np.array, y_train: np.array, metric = \"accuracy\", k=10):\n",
    "        evaluation = []\n",
    "        for i in range(k):\n",
    "            X_test_fold = X_train[int((i / k) * len(X_train)):int(((i + 1) / k) * len(X_train))]\n",
    "            y_test_fold = y_train[int((i / k) * len(y_train)):int(((i + 1) / k) * len(y_train))]\n",
    "            X_train_fold = np.concatenate(\n",
    "                (X_train[:int((i / k) * len(X_train))], X_train[int(((i + 1) / k) * len(X_train)):]))\n",
    "            y_train_fold = np.concatenate(\n",
    "                (y_train[:int((i / k) * len(y_train))], y_train[int(((i + 1) / k) * len(y_train)):]))\n",
    "            self.skmodel.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = self.skmodel.predict(X_test_fold)\n",
    "            if metric == \"accuracy\":\n",
    "                evaluation.append(self.accuracy(y_test_fold, y_pred))\n",
    "            else : \n",
    "                evaluation.append(self.f1_score(y_test_fold, y_pred))\n",
    "\n",
    "                \n",
    "            evaluation.append(self.f1_score(y_test_fold, y_pred))\n",
    "        return np.mean(evaluation)\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def f1_score(y_true, y_predict):\n",
    "        p = 0\n",
    "        r = 0\n",
    "        n_classes = y_true.nunique()\n",
    "        for i in range(n_classes):\n",
    "            tp = sum(((y_true == i) & (y_predict == i)))\n",
    "            fp = sum(((y_true != i) & (y_predict == i)))\n",
    "            fn = sum(((y_true == i) & (y_predict != i)))\n",
    "            p += tp / (tp + fp)\n",
    "            r += tp / (tp + fn)\n",
    "        p = p / n_classes\n",
    "        r = r / n_classes\n",
    "        return 2 * p * r / (p + r)\n",
    "    @staticmethod    \n",
    "    def accuracy (y_true, y_predict):\n",
    "        good_predictions = np.sum((y_true == y_predict)*1)\n",
    "        return good_predictions /len(y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}